#!/usr/bin/env python3

"""
Excelè®­ç»ƒæ•°æ®å¤„ç†è„šæœ¬
ç”¨äºå¤„ç†æ©™å•¦-query_RL_è®­ç»ƒé›†.xlsxæ–‡ä»¶ï¼Œç”Ÿæˆè®­ç»ƒæ•°æ®
"""

import pandas as pd
import re
import json
import logging
import argparse
import random
from typing import List, Dict, Any, Optional
from pathlib import Path

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class ExcelDataProcessor:
    """Excelæ•°æ®å¤„ç†å™¨"""
    
    def __init__(self, excel_path: str):
        """
        åˆå§‹åŒ–Excelæ•°æ®å¤„ç†å™¨
        
        Args:
            excel_path: Excelæ–‡ä»¶è·¯å¾„
        """
        self.excel_path = Path(excel_path)
        self.data = None
        
        # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not self.excel_path.exists():
            raise FileNotFoundError(f"Excelæ–‡ä»¶ä¸å­˜åœ¨: {excel_path}")
        
        logger.info(f"åˆå§‹åŒ–Excelæ•°æ®å¤„ç†å™¨ï¼Œæ–‡ä»¶è·¯å¾„: {excel_path}")
    
    def read_excel(self) -> pd.DataFrame:
        """
        è¯»å–Excelæ–‡ä»¶
        
        Returns:
            pd.DataFrame: è¯»å–çš„æ•°æ®æ¡†
        """
        try:
            logger.info(f"å¼€å§‹è¯»å–Excelæ–‡ä»¶: {self.excel_path}")
            
            # è¯»å–Excelæ–‡ä»¶
            self.data = pd.read_excel(self.excel_path)
            
            logger.info(f"Excelæ–‡ä»¶è¯»å–æˆåŠŸï¼Œå…± {len(self.data)} è¡Œæ•°æ®")
            logger.info(f"åˆ—å: {list(self.data.columns)}")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…éœ€çš„åˆ—ï¼ˆæ”¯æŒå¤šç§åˆ—åï¼‰
            dialogue_column = None
            possible_column_names = ['å†å²ä¼ å‚ä¸Šä¸‹æ–‡', 'æœ€ç»ˆä¼ å‚ä¸Šä¸‹æ–‡', 'å¯¹è¯å†å²', 'å†å²å¯¹è¯']
            
            for col_name in possible_column_names:
                if col_name in self.data.columns:
                    dialogue_column = col_name
                    break
            
            if dialogue_column is None:
                raise ValueError(f"Excelæ–‡ä»¶ä¸­ç¼ºå°‘å¿…éœ€çš„å¯¹è¯æ•°æ®åˆ—ï¼ŒæœŸæœ›çš„åˆ—å: {possible_column_names}ï¼Œå®é™…åˆ—å: {list(self.data.columns)}")
            
            # é‡å‘½ååˆ—åˆ°æ ‡å‡†åç§°
            self.data = self.data.rename(columns={dialogue_column: 'å†å²ä¼ å‚ä¸Šä¸‹æ–‡'})
            logger.info(f"ä½¿ç”¨åˆ— '{dialogue_column}' ä½œä¸ºå¯¹è¯æ•°æ®åˆ—")
            
            return self.data
            
        except Exception as e:
            logger.error(f"è¯»å–Excelæ–‡ä»¶å¤±è´¥: {e}")
            raise
    
    def extract_query_and_history(self, dialogue_text: str) -> Dict[str, str]:
        """
        ä»å¯¹è¯æ–‡æœ¬ä¸­æå–ç”¨æˆ·æŸ¥è¯¢å’Œå†å²å¯¹è¯
        ä¿ç•™[å®¢æˆ·][æ—¶é—´æˆ³]:å‰ç¼€æ ¼å¼
        
        Args:
            dialogue_text: å®Œæ•´çš„å¯¹è¯å†å²æ–‡æœ¬
        
        Returns:
            dict: åŒ…å«history_chatå’Œqueryçš„å­—å…¸
        """
        try:
            # é¢„å¤„ç†å¯¹è¯æ–‡æœ¬
            dialogue_text = self.preprocess_dialogue(dialogue_text)
            
            # æŒ‰è¡Œåˆ†å‰²å¯¹è¯
            lines = dialogue_text.strip().split('\n')
            
            # æ‰¾åˆ°æœ€åä¸€ä¸ªå®¢æˆ·å‘è¨€
            last_customer_line = None
            history_lines = []
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                    
                # è§£æå‘è¨€è€…
                if line.startswith('[å®¢æˆ·]'):
                    last_customer_line = line
                    history_lines.append(line)
                elif line.startswith('[é”€å”®]'):
                    history_lines.append(line)
                else:
                    # å¤„ç†å¯èƒ½çš„æ ¼å¼é—®é¢˜
                    history_lines.append(line)
            
            # æå–æŸ¥è¯¢ï¼ˆæœ€åä¸€ä¸ªå®¢æˆ·çš„å‘è¨€å†…å®¹ï¼Œä¿ç•™å®Œæ•´å‰ç¼€ï¼‰
            if last_customer_line:
                query_content = last_customer_line  # ä¿ç•™å®Œæ•´æ ¼å¼ï¼ŒåŒ…æ‹¬[å®¢æˆ·][æ—¶é—´æˆ³]:å‰ç¼€
            else:
                query_content = ""
            
            # æ„å»ºå†å²å¯¹è¯ï¼ˆé™¤æœ€åä¸€ä¸ªå®¢æˆ·å‘è¨€å¤–çš„æ‰€æœ‰å†…å®¹ï¼‰
            if last_customer_line and last_customer_line in history_lines:
                history_lines.remove(last_customer_line)
            
            history_chat = '\n'.join(history_lines)
            
            result = {
                "history_chat": history_chat,
                "query": query_content
            }
            
            logger.debug(f"æå–ç»“æœ - history_chaté•¿åº¦: {len(history_chat)}, query: {query_content}")
            
            return result
            
        except Exception as e:
            logger.error(f"æå–æŸ¥è¯¢å’Œå†å²å¯¹è¯å¤±è´¥: {e}")
            return {
                "history_chat": "",
                "query": ""
            }
    
    def preprocess_dialogue(self, dialogue_text: str) -> str:
        """
        é¢„å¤„ç†å¯¹è¯æ–‡æœ¬
        
        Args:
            dialogue_text: åŸå§‹å¯¹è¯æ–‡æœ¬
        
        Returns:
            str: é¢„å¤„ç†åçš„å¯¹è¯æ–‡æœ¬
        """
        try:
            # æ ‡å‡†åŒ–ç©ºç™½å­—ç¬¦ï¼Œä½†ä¿ç•™æ¢è¡Œç¬¦
            lines = dialogue_text.strip().split('\n')
            processed_lines = []
            
            for line in lines:
                # ç§»é™¤è¡Œé¦–è¡Œå°¾çš„ç©ºç™½å­—ç¬¦ï¼Œä½†ä¿ç•™å†…å®¹
                processed_line = line.strip()
                if processed_line:  # åªä¿ç•™éç©ºè¡Œ
                    processed_lines.append(processed_line)
            
            # é‡æ–°ç»„åˆ
            processed_text = '\n'.join(processed_lines)
            
            return processed_text
            
        except Exception as e:
            logger.warning(f"é¢„å¤„ç†å¯¹è¯æ–‡æœ¬å¤±è´¥: {e}")
            return dialogue_text
    
    def load_prompt_template(self, template_path: str) -> str:
        """
        åŠ è½½promptæ¨¡æ¿
        
        Args:
            template_path: æ¨¡æ¿æ–‡ä»¶è·¯å¾„
        
        Returns:
            str: æ¨¡æ¿å†…å®¹
        """
        try:
            with open(template_path, 'r', encoding='utf-8') as f:
                template_content = f.read()
            
            logger.info(f"æˆåŠŸåŠ è½½promptæ¨¡æ¿: {template_path}")
            return template_content
            
        except Exception as e:
            logger.error(f"åŠ è½½promptæ¨¡æ¿å¤±è´¥: {e}")
            raise
    
    def combine_prompt(self, template: str, data: Dict[str, str]) -> str:
        """
        ç»„åˆpromptæ¨¡æ¿å’Œæ•°æ®
        
        Args:
            template: promptæ¨¡æ¿
            data: åŒ…å«history_chat, query, user_profile, thoughtçš„æ•°æ®
        
        Returns:
            str: ç»„åˆåçš„å®Œæ•´prompt
        """
        try:
            # å‡†å¤‡æ¨¡æ¿å‚æ•°
            template_data = {
                "history_chat": data.get("history_chat", ""),
                "query": data.get("query", ""),
                "thought": data.get("thought", "")
            }
            
            # ä½¿ç”¨ç®€å•çš„å­—ç¬¦ä¸²æ›¿æ¢ï¼ˆé¿å…Jinja2ä¾èµ–ï¼‰
            combined_prompt = template
            
            # æ›¿æ¢å ä½ç¬¦
            combined_prompt = combined_prompt.replace("{{history_chat}}", template_data["history_chat"])
            combined_prompt = combined_prompt.replace("{{query}}", template_data["query"])
            combined_prompt = combined_prompt.replace("{{thought}}", template_data["thought"])
            
            # å¤„ç†æ¡ä»¶è¯­å¥ï¼ˆç®€å•å®ç°ï¼‰
            # ç§»é™¤æ²¡æœ‰thoughtçš„æ¡ä»¶å—
            if not template_data["thought"]:
                # ç§»é™¤ {% if thought %} ... {% endif %} å—
                import re
                pattern = r'\{% if thought %\}(.*?)\{% endif %\}'
                combined_prompt = re.sub(pattern, '', combined_prompt, flags=re.DOTALL)
            
            logger.debug(f"Promptç»„åˆå®Œæˆï¼Œé•¿åº¦: {len(combined_prompt)}")
            return combined_prompt
            
        except Exception as e:
            logger.error(f"Promptç»„åˆå¤±è´¥: {e}")
            raise
    
    def generate_training_samples(self, prompt_template_path: str) -> List[Dict[str, Any]]:
        """
        ç”Ÿæˆè®­ç»ƒæ ·æœ¬ v2.0 - æ”¯æŒåŒæ¨¡å‹GRPOæ¶æ„
        
        Args:
            prompt_template_path: promptæ¨¡æ¿æ–‡ä»¶è·¯å¾„
        
        Returns:
            List[Dict]: è®­ç»ƒæ ·æœ¬åˆ—è¡¨
        """
        if self.data is None:
            self.read_excel()
        
        # åŠ è½½promptæ¨¡æ¿
        template = self.load_prompt_template(prompt_template_path)
        
        training_samples = []
        
        for idx, row in self.data.iterrows():
            try:
                dialogue_text = row['å†å²ä¼ å‚ä¸Šä¸‹æ–‡']
                
                if pd.isna(dialogue_text) or not str(dialogue_text).strip():
                    logger.warning(f"ç¬¬ {idx} è¡Œæ•°æ®ä¸ºç©ºï¼Œè·³è¿‡")
                    continue
                
                # æå–æŸ¥è¯¢å’Œå†å²å¯¹è¯
                parsed_data = self.extract_query_and_history(str(dialogue_text))
                
                # éªŒè¯æå–ç»“æœ
                if not parsed_data["query"]:
                    logger.warning(f"ç¬¬ {idx} è¡Œæœªèƒ½æå–åˆ°ç”¨æˆ·æŸ¥è¯¢ï¼Œè·³è¿‡")
                    continue
                
                # æ·»åŠ å¯é€‰å­—æ®µï¼ˆExcelä¸­æ²¡æœ‰ï¼Œè®¾ä¸ºç©ºï¼‰
                parsed_data["user_profile"] = ""
                parsed_data["thought"] = ""
                
                # ç»„åˆprompt
                complete_prompt = self.combine_prompt(template, parsed_data)
                
                # ğŸ”¥ æ–°å¢ï¼šæ„å»ºç¬¦åˆGRPOæ¶æ„çš„è®­ç»ƒæ ·æœ¬æ ¼å¼
                training_sample = {
                    "prompt_id": f"train_{idx:06d}",
                    "original_dialogue": str(dialogue_text),
                    "prompt": complete_prompt,
                    "parsed_data": parsed_data,
                    
                    # ğŸ”¥ æ–°å¢ï¼šæ¨¡å‹é…ç½®
                    "model_configs": {
                        "actor_model": {
                            "model_name": "Qwen3-8B-Instruct",
                            "rag_endpoint": "/chat_8b",
                            "input_format": "structured_json",
                            "expected_output": ["user_profile", "rewritten_query", "history_summary"]
                        },
                        "reference_model": {
                            "model_name": "Qwen3-32B-Instruct",
                            "rag_endpoint": "/chat",
                            "input_format": "raw_prompt",
                            "expected_output": "full_response"
                        }
                    },
                    
                    # ğŸ”¥ æ–°å¢ï¼šè¯„åˆ†é…ç½®
                    "reward_config": {
                        "scoring_model": "GPT-5",
                        "scoring_dimensions": ["è´¨é‡æå‡åº¦", "ç›¸å…³æ€§å‡†ç¡®æ€§", "ä¿¡æ¯å®Œæ•´æ€§", "æ£€ç´¢æœ‰æ•ˆæ€§"],
                        "comparison_mode": "dual_model"
                    },
                    
                    # ğŸ”¥ ä¿ç•™åŸæœ‰å­—æ®µç”¨äºå‘åå…¼å®¹
                    "data_source": "sales_rag_rl",
                    "actor_input": {
                        "history_chat": parsed_data["history_chat"],
                        "query": parsed_data["query"],
                        "user_profile": parsed_data["user_profile"],
                        "thought": parsed_data["thought"],
                        "original_dialogue": str(dialogue_text)
                    },
                    "reward_model": {
                        "type": "gpt5_comparison",
                        "baseline_model": "Qwen3-32B-Instruct",
                        "scoring_dimensions": ["è´¨é‡æå‡åº¦", "ç›¸å…³æ€§å‡†ç¡®æ€§", "ä¿¡æ¯å®Œæ•´æ€§", "æ£€ç´¢æœ‰æ•ˆæ€§"]
                    },
                    "expected_output_format": {
                        "user_profile": "string",
                        "rewritten_query": "string",
                        "history_summary": "string"
                    },
                    "metadata": {
                        "source_file": str(self.excel_path),
                        "row_index": idx,
                        "processing_timestamp": pd.Timestamp.now().isoformat(),
                        "architecture_version": "v2.0"
                    }
                }
                
                training_samples.append(training_sample)
                
            except Exception as e:
                logger.error(f"å¤„ç†ç¬¬ {idx} è¡Œæ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                continue
        
        logger.info(f"æˆåŠŸç”Ÿæˆ {len(training_samples)} ä¸ªè®­ç»ƒæ ·æœ¬ï¼ˆv2.0 GRPOæ¶æ„ï¼‰")
        return training_samples
    
    def save_training_samples(self, output_path: str, samples: List[Dict[str, Any]]) -> None:
        """
        ä¿å­˜è®­ç»ƒæ ·æœ¬åˆ°æ–‡ä»¶
        
        Args:
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            samples: è®­ç»ƒæ ·æœ¬åˆ—è¡¨
        """
        try:
            output_path = Path(output_path)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©ä¿å­˜æ ¼å¼
            if output_path.suffix.lower() == '.jsonl':
                with open(output_path, 'w', encoding='utf-8') as f:
                    for sample in samples:
                        f.write(json.dumps(sample, ensure_ascii=False) + '\n')
            elif output_path.suffix.lower() == '.json':
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(samples, f, ensure_ascii=False, indent=2)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„è¾“å‡ºæ ¼å¼: {output_path.suffix}")
            
            logger.info(f"è®­ç»ƒæ ·æœ¬å·²ä¿å­˜åˆ°: {output_path}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜è®­ç»ƒæ ·æœ¬å¤±è´¥: {e}")
            raise
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict: ç»Ÿè®¡ä¿¡æ¯
        """
        if self.data is None:
            self.read_excel()
        
        # åŸºæœ¬ç»Ÿè®¡
        total_rows = len(self.data)
        non_empty_rows = len(self.data.dropna(subset=['å†å²ä¼ å‚ä¸Šä¸‹æ–‡']))
        
        # å¯¹è¯é•¿åº¦ç»Ÿè®¡
        dialogue_lengths = []
        query_lengths = []
        
        for idx, row in self.data.iterrows():
            dialogue_text = row['å†å²ä¼ å‚ä¸Šä¸‹æ–‡']
            if pd.isna(dialogue_text):
                continue
            
            dialogue_text = str(dialogue_text)
            dialogue_lengths.append(len(dialogue_text))
            
            # æå–æŸ¥è¯¢é•¿åº¦
            parsed_data = self.extract_query_and_history(dialogue_text)
            query_lengths.append(len(parsed_data["query"]))
        
        statistics = {
            "total_rows": total_rows,
            "non_empty_rows": non_empty_rows,
            "empty_rows": total_rows - non_empty_rows,
            "avg_dialogue_length": sum(dialogue_lengths) / len(dialogue_lengths) if dialogue_lengths else 0,
            "max_dialogue_length": max(dialogue_lengths) if dialogue_lengths else 0,
            "min_dialogue_length": min(dialogue_lengths) if dialogue_lengths else 0,
            "avg_query_length": sum(query_lengths) / len(query_lengths) if query_lengths else 0,
            "max_query_length": max(query_lengths) if query_lengths else 0,
            "min_query_length": min(query_lengths) if query_lengths else 0,
        }
        
        return statistics
    
    def build_validation_dataset(self, sample_size: int = 100, method: str = "random",
                               seed: int = 42) -> List[Dict[str, Any]]:
        """
        æ„å»ºéªŒè¯æ•°æ®é›† - ä»åŸå§‹æ•°æ®ä¸­éšæœºé‡‡æ ·
        
        Args:
            sample_size: é‡‡æ ·å¤§å°
            method: é‡‡æ ·æ–¹æ³•
            seed: éšæœºç§å­
            
        Returns:
            List[Dict]: éªŒè¯æ ·æœ¬åˆ—è¡¨
        """
        if self.data is None:
            self.read_excel()
        
        # è®¾ç½®éšæœºç§å­
        random.seed(seed)
        
        # è·å–æ‰€æœ‰å¯¹è¯æ•°æ®
        all_dialogues = []
        for idx, row in self.data.iterrows():
            dialogue_text = row['å†å²ä¼ å‚ä¸Šä¸‹æ–‡']
            if pd.notna(dialogue_text) and str(dialogue_text).strip():
                all_dialogues.append(str(dialogue_text).strip())
        
        if not all_dialogues:
            logger.warning("æ²¡æœ‰å¯ç”¨çš„å¯¹è¯æ•°æ®ç”¨äºæ„å»ºéªŒè¯æ•°æ®é›†")
            return []
        
        # æ ¹æ®é‡‡æ ·å¤§å°è°ƒæ•´
        if sample_size > len(all_dialogues):
            logger.warning(f"é‡‡æ ·å¤§å° {sample_size} å¤§äºå¯ç”¨æ•°æ®é‡ {len(all_dialogues)}ï¼Œä½¿ç”¨å…¨éƒ¨æ•°æ®")
            sample_size = len(all_dialogues)
        
        # æ‰§è¡Œé‡‡æ ·
        if method == "random":
            sampled_dialogues = random.sample(all_dialogues, sample_size)
        elif method == "stratified":
            # åˆ†å±‚é‡‡æ ·ï¼šæ ¹æ®å¯¹è¯é•¿åº¦åˆ†å±‚
            dialogues_by_length = {}
            for dialogue in all_dialogues:
                length_category = len(dialogue) // 200  # æ¯200å­—ç¬¦ä¸ºä¸€ä¸ªå±‚çº§
                if length_category not in dialogues_by_length:
                    dialogues_by_length[length_category] = []
                dialogues_by_length[length_category].append(dialogue)
            
            sampled_dialogues = []
            samples_per_layer = sample_size // len(dialogues_by_length)
            remainder = sample_size % len(dialogues_by_length)
            
            for i, (layer, layer_data) in enumerate(dialogues_by_length.items()):
                layer_sample_size = samples_per_layer + (1 if i < remainder else 0)
                if layer_sample_size > len(layer_data):
                    layer_sample_size = len(layer_data)
                sampled_dialogues.extend(random.sample(layer_data, layer_sample_size))
        else:
            # é»˜è®¤ä½¿ç”¨éšæœºé‡‡æ ·
            sampled_dialogues = random.sample(all_dialogues, sample_size)
        
        # è½¬æ¢ä¸ºéªŒè¯æ•°æ®é›†æ ¼å¼
        validation_samples = []
        for idx, dialogue_text in enumerate(sampled_dialogues):
            validation_sample = {
                "prompt": dialogue_text,
                "data_source": "sales_rag",
                "reward_model": {"ground_truth": {}},
                "metadata": {
                    "source_file": str(self.excel_path),
                    "sample_index": idx,
                    "sampling_method": method,
                    "sampling_timestamp": pd.Timestamp.now().isoformat()
                }
            }
            validation_samples.append(validation_sample)
        
        logger.info(f"æˆåŠŸæ„å»º {len(validation_samples)} ä¸ªéªŒè¯æ ·æœ¬ (æ–¹æ³•: {method})")
        return validation_samples
    
    def split_train_val(self, train_ratio: float = 0.8, val_ratio: float = 0.2,
                       seed: int = 42) -> tuple:
        """
        å°†æ•°æ®é›†åˆ†å‰²ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†
        
        Args:
            train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
            val_ratio: éªŒè¯é›†æ¯”ä¾‹
            seed: éšæœºç§å­
            
        Returns:
            tuple: (è®­ç»ƒæ ·æœ¬åˆ—è¡¨, éªŒè¯æ ·æœ¬åˆ—è¡¨)
        """
        if self.data is None:
            self.read_excel()
        
        # è®¾ç½®éšæœºç§å­
        random.seed(seed)
        
        # è·å–æ‰€æœ‰æœ‰æ•ˆæ•°æ®ç´¢å¼•
        valid_indices = []
        for idx, row in self.data.iterrows():
            dialogue_text = row['å†å²ä¼ å‚ä¸Šä¸‹æ–‡']
            if pd.notna(dialogue_text) and str(dialogue_text).strip():
                valid_indices.append(idx)
        
        if not valid_indices:
            logger.warning("æ²¡æœ‰å¯ç”¨çš„æ•°æ®")
            return [], []
        
        # éšæœºæ‰“ä¹±ç´¢å¼•
        random.shuffle(valid_indices)
        
        # è®¡ç®—åˆ†å‰²ç‚¹
        total_size = len(valid_indices)
        train_size = int(total_size * train_ratio)
        
        # åˆ†å‰²æ•°æ®
        train_indices = valid_indices[:train_size]
        val_indices = valid_indices[train_size:]
        
        logger.info(f"æ•°æ®é›†åˆ†å‰²å®Œæˆ - è®­ç»ƒé›†: {len(train_indices)}, éªŒè¯é›†: {len(val_indices)}")
        return train_indices, val_indices


def main():
    """ä¸»å‡½æ•° - é»˜è®¤åŒæ—¶ç”Ÿæˆè®­ç»ƒé›†å’ŒéªŒè¯é›†"""
    parser = argparse.ArgumentParser(description='Excelè®­ç»ƒæ•°æ®å¤„ç† - ä¸€é”®ç”Ÿæˆè®­ç»ƒæ•°æ®å’ŒéªŒè¯æ•°æ®é›†')
    parser.add_argument('--input', '-i', type=str, required=True, help='Excelæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', type=str, required=True, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆè®­ç»ƒæ•°æ®ï¼‰')
    parser.add_argument('--template', '-t', type=str, required=True, help='Promptæ¨¡æ¿æ–‡ä»¶è·¯å¾„')
    
    # éªŒè¯æ•°æ®é›†å‚æ•°ï¼ˆç°åœ¨æœ‰äº†åˆç†çš„é»˜è®¤å€¼ï¼‰
    parser.add_argument('--val-output', '-vo', type=str, help='éªŒè¯æ•°æ®é›†è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: è‡ªåŠ¨ç”Ÿæˆï¼‰')
    parser.add_argument('--val-size', '-vs', type=int, default=100, help='éªŒè¯é›†å¤§å° (é»˜è®¤: 100)')
    parser.add_argument('--val-method', '-vm', type=str, default='random',
                       choices=['random', 'stratified'], help='éªŒè¯é›†é‡‡æ ·æ–¹æ³• (é»˜è®¤: random)')
    parser.add_argument('--split-ratio', '-sr', type=float, nargs=2,
                       help='è®­ç»ƒé›†å’ŒéªŒè¯é›†åˆ†å‰²æ¯”ä¾‹ï¼Œä¾‹å¦‚: 0.8 0.2')
    parser.add_argument('--no-val', action='store_true', help='ä¸ç”ŸæˆéªŒè¯æ•°æ®é›†')
    
    parser.add_argument('--statistics', '-s', action='store_true', help='æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯')
    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†è¾“å‡º')
    parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­ (é»˜è®¤: 42)')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    try:
        # åˆ›å»ºæ•°æ®å¤„ç†å™¨
        processor = ExcelDataProcessor(args.input)
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        if args.statistics:
            stats = processor.get_statistics()
            print("æ•°æ®ç»Ÿè®¡ä¿¡æ¯:")
            for key, value in stats.items():
                print(f"  {key}: {value}")
            print()
        
        # ç”Ÿæˆè®­ç»ƒæ ·æœ¬
        samples = processor.generate_training_samples(args.template)
        
        # ä¿å­˜è®­ç»ƒæ•°æ®
        processor.save_training_samples(args.output, samples)
        print(f"è®­ç»ƒæ ·æœ¬å·²ä¿å­˜åˆ°: {args.output}")
        print(f"æˆåŠŸå¤„ç† {len(samples)} ä¸ªè®­ç»ƒæ ·æœ¬")
        
        # é»˜è®¤ç”ŸæˆéªŒè¯æ•°æ®é›†ï¼ˆé™¤éæ˜ç¡®æŒ‡å®š --no-valï¼‰
        if not args.no_val:
            print("\n" + "="*50)
            print("å¼€å§‹è‡ªåŠ¨æ„å»ºéªŒè¯æ•°æ®é›†...")
            
            # è‡ªåŠ¨ç”ŸæˆéªŒè¯é›†è¾“å‡ºè·¯å¾„
            if not args.val_output:
                if args.output.endswith('.jsonl'):
                    args.val_output = args.output.replace('.jsonl', '_val.jsonl')
                elif args.output.endswith('.json'):
                    args.val_output = args.output.replace('.json', '_val.json')
                else:
                    args.val_output = args.output + '_val.jsonl'
            
            if args.split_ratio:
                # ä½¿ç”¨åˆ†å‰²æ¯”ä¾‹æ–¹å¼
                if len(args.split_ratio) != 2:
                    raise ValueError("è¯·æä¾›ä¸¤ä¸ªæ¯”ä¾‹å€¼: è®­ç»ƒé›†æ¯”ä¾‹ éªŒè¯é›†æ¯”ä¾‹")
                
                train_ratio, val_ratio = args.split_ratio
                if abs(train_ratio + val_ratio - 1.0) > 0.01:
                    logger.warning(f"æ¯”ä¾‹ä¹‹å’Œä¸ç­‰äº1: {train_ratio} + {val_ratio} = {train_ratio + val_ratio}")
                
                train_indices, val_indices = processor.split_train_val(train_ratio, val_ratio, args.seed)
                
                # æ„å»ºéªŒè¯æ ·æœ¬
                val_samples = []
                for idx in val_indices[:min(len(val_indices), args.val_size)]:
                    row = processor.data.iloc[idx]
                    dialogue_text = row['å†å²ä¼ å‚ä¸Šä¸‹æ–‡']
                    if pd.notna(dialogue_text) and str(dialogue_text).strip():
                        val_sample = {
                            "prompt": str(dialogue_text).strip(),
                            "data_source": "sales_rag",
                            "reward_model": {"ground_truth": {}},
                            "metadata": {
                                "source_file": str(processor.excel_path),
                                "sample_index": idx,
                                "sampling_method": "split_ratio",
                                "split_ratio": f"{train_ratio}:{val_ratio}"
                            }
                        }
                        val_samples.append(val_sample)
                
                if val_samples:
                    processor.save_training_samples(args.val_output, val_samples)
                    print(f"éªŒè¯æ•°æ®é›†å·²ä¿å­˜åˆ°: {args.val_output}")
                    print(f"éªŒè¯æ ·æœ¬æ•°é‡: {len(val_samples)}")
                
            else:
                # é»˜è®¤ä½¿ç”¨éšæœºé‡‡æ ·æ–¹å¼
                val_samples = processor.build_validation_dataset(
                    sample_size=args.val_size,
                    method=args.val_method,
                    seed=args.seed
                )
                
                if val_samples:
                    processor.save_training_samples(args.val_output, val_samples)
                    print(f"éªŒè¯æ•°æ®é›†å·²ä¿å­˜åˆ°: {args.val_output}")
                    print(f"éªŒè¯æ ·æœ¬æ•°é‡: {len(val_samples)}")
                    print(f"é‡‡æ ·æ–¹æ³•: {args.val_method}")
        
        print("\n" + "="*50)
        print("æ•°æ®å¤„ç†å®Œæˆï¼")
        print(f"  è¾“å…¥æ–‡ä»¶: {args.input}")
        print(f"  è®­ç»ƒæ•°æ®: {args.output} ({len(samples)} æ ·æœ¬)")
        if not args.no_val and 'val_samples' in locals() and val_samples:
            print(f"  éªŒè¯æ•°æ®: {args.val_output} ({len(val_samples)} æ ·æœ¬)")
        elif args.no_val:
            print("  éªŒè¯æ•°æ®: æœªç”Ÿæˆ (ä½¿ç”¨ --no-val å‚æ•°)")
        elif args.split_ratio and 'val_samples' in locals():
            val_output_path = args.val_output or args.output.replace('.jsonl', '_val.jsonl').replace('.json', '_val.json')
            print(f"  éªŒè¯æ•°æ®: {val_output_path} ({len(val_samples)} æ ·æœ¬)")
            
    except Exception as e:
        logger.error(f"é”™è¯¯: {e}")
        return 1
    
    return 0


if __name__ == '__main__':
    exit(main())