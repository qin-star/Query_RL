#!/bin/bash
# GPU å†…å­˜æ£€æŸ¥è„šæœ¬

echo "ğŸ® GPU å†…å­˜çŠ¶æ€æ£€æŸ¥"
echo "================================================"

# æ£€æŸ¥ nvidia-smi æ˜¯å¦å¯ç”¨
if ! command -v nvidia-smi &> /dev/null; then
    echo "âŒ nvidia-smi ä¸å¯ç”¨"
    exit 1
fi

# æ˜¾ç¤º GPU ä¿¡æ¯
echo ""
echo "ğŸ“Š GPU æ€»è§ˆï¼š"
nvidia-smi --query-gpu=index,name,memory.total,memory.free,memory.used --format=csv

# æ˜¾ç¤ºè¯¦ç»†çš„è¿›ç¨‹ä¿¡æ¯
echo ""
echo "ğŸ” GPU è¿›ç¨‹è¯¦æƒ…ï¼š"
nvidia-smi

# è®¡ç®—å¯ç”¨å†…å­˜ç™¾åˆ†æ¯”
echo ""
echo "ğŸ“ˆ å†…å­˜ä½¿ç”¨åˆ†æï¼š"
python3 -c "
import subprocess
import re

result = subprocess.run(['nvidia-smi', '--query-gpu=index,memory.total,memory.free,memory.used', '--format=csv,noheader,nounits'], 
                       capture_output=True, text=True)

for line in result.stdout.strip().split('\n'):
    parts = [x.strip() for x in line.split(',')]
    if len(parts) >= 4:
        idx, total, free, used = parts[0], float(parts[1]), float(parts[2]), float(parts[3])
        free_pct = (free / total) * 100
        used_pct = (used / total) * 100
        
        print(f'GPU {idx}:')
        print(f'  æ€»å†…å­˜: {total/1024:.2f} GB')
        print(f'  å·²ç”¨: {used/1024:.2f} GB ({used_pct:.1f}%)')
        print(f'  å¯ç”¨: {free/1024:.2f} GB ({free_pct:.1f}%)')
        
        # è®¡ç®—ä¸åŒ utilization è®¾ç½®éœ€è¦çš„å†…å­˜
        for util in [0.4, 0.45, 0.5, 0.55, 0.6]:
            required = total * util / 1024
            if free >= total * util:
                status = 'âœ“'
            else:
                status = 'âœ—'
            print(f'  {status} gpu_memory_utilization={util}: éœ€è¦ {required:.2f} GB')
        print()
"

# å»ºè®®
echo "================================================"
echo "ğŸ’¡ å»ºè®®ï¼š"
echo ""
echo "1. å¦‚æœæœ‰å…¶ä»–è¿›ç¨‹å ç”¨ GPUï¼Œè€ƒè™‘ï¼š"
echo "   - æ€æ‰ä¸éœ€è¦çš„è¿›ç¨‹"
echo "   - ä½¿ç”¨å…¶ä»–ç©ºé—²çš„ GPU"
echo "   - é™ä½ gpu_memory_utilization"
echo ""
echo "2. å½“å‰é…ç½®å·²è®¾ç½®ä¸º 0.45ï¼Œå¦‚æœè¿˜ä¸å¤Ÿï¼š"
echo "   - è¿›ä¸€æ­¥é™ä½åˆ° 0.4 æˆ– 0.35"
echo "   - å‡å° max_num_batched_tokens"
echo "   - å‡å° max_num_seqs"
echo ""
echo "3. æ¸…ç† GPU å†…å­˜ï¼š"
echo "   python -c 'import torch; torch.cuda.empty_cache()'"
echo "================================================"
