#!/bin/bash
# æ··åˆGRPOè®­ç»ƒè„šæœ¬ - GPUå¯è§æ€§ä¿®å¤ç‰ˆï¼ˆåŸºäºRayæ¡†æ¶æœ€ä½³å®è·µï¼‰
# å‚è€ƒæŠ€æœ¯åšå®¢ï¼šåœ¨Rayæ¡†æ¶ä¸‹æ­£ç¡®è®¾ç½®GPUå¯è§æ€§
# å…³é”®ä¿®æ­£ï¼šåœ¨Rayåˆå§‹åŒ–å‰è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿è®¾å¤‡æ˜ å°„æ­£ç¡®

set -x

echo "ğŸš€ å¯åŠ¨æ··åˆGRPOè®­ç»ƒï¼Œç›®æ ‡GPU: 4,5,6,7"
echo "ğŸ“‹ è®­ç»ƒé…ç½®ï¼š"
echo "  - æ¨¡å‹: Qwen3-8B"
echo "  - ç®—æ³•: æ··åˆGRPO (GRPOæƒé‡: 0.7, è¾…åŠ©æƒé‡: 0.3)"
echo "  - ç»„å¤§å°: 5"
echo "  - åŠ¨æ€æƒé‡: å¯ç”¨"
echo "  - GPT-5è¾…åŠ©å¥–åŠ±: ç»„å†…ä¸­å¿ƒåŒ–"

# === æ–¹æ³•ä¸€ï¼šåœ¨shellçº§åˆ«è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆåŸºç¡€æ–¹æ¡ˆï¼‰ ===
export CUDA_VISIBLE_DEVICES=4,5,6,7
export PYTHONPATH=/home/jovyan2/query_rl:$PYTHONPATH

echo "âœ… Shellçº§åˆ« - CUDA_VISIBLE_DEVICES è®¾ç½®ä¸º: $CUDA_VISIBLE_DEVICES"
echo "âœ… Shellçº§åˆ« - PYTHONPATH è®¾ç½®ä¸º: $PYTHONPATH"

# === æ–¹æ³•äºŒï¼šPythonè¿è¡Œæ—¶åŠ¨æ€è®¾ç½®ï¼ˆæ¨èæ–¹æ¡ˆï¼‰ ===
# å‚è€ƒåšå®¢å»ºè®®ï¼šåœ¨Rayåˆå§‹åŒ–å‰å¼ºåˆ¶è®¾å®šç¯å¢ƒå˜é‡
python3 -c "
import os
import sys
import subprocess

# æŠ€æœ¯å…³é”®ç‚¹ï¼šåœ¨Rayåˆå§‹åŒ–å‰è®¾ç½®GPUå¯è§æ€§
os.environ['CUDA_VISIBLE_DEVICES'] = '4,5,6,7'
os.environ['PYTHONPATH'] = '/home/jovyan2/query_rl:' + os.environ.get('PYTHONPATH', '')

# ç¡®ä¿Pythonèƒ½å¤Ÿæ‰¾åˆ°verlæ¨¡å—
sys.path.insert(0, '/home/jovyan2/query_rl')

print(f'âœ… Pythonè¿è¡Œæ—¶ - CUDA_VISIBLE_DEVICES: {os.environ.get(\"CUDA_VISIBLE_DEVICES\")}')
print(f'âœ… Pythonè¿è¡Œæ—¶ - PYTHONPATH: {os.environ.get(\"PYTHONPATH\")}')
print(f'âœ… Pythonè¿è¡Œæ—¶ - sys.path: {sys.path[:2]}')

# è®¾å¤‡æ˜ å°„éªŒè¯ï¼šæ£€æŸ¥é€»è¾‘GPUä¸ç‰©ç†GPUçš„å¯¹åº”å…³ç³»
try:
    import torch
    print(f'âœ… PyTorchå¯è§GPUæ•°é‡: {torch.cuda.device_count()}')
    if torch.cuda.is_available():
        for i in range(torch.cuda.device_count()):
            gpu_name = torch.cuda.get_device_name(i)
            print(f'  é€»è¾‘GPU {i} -> ç‰©ç†GPU: {gpu_name}')
except Exception as e:
    print(f'âš ï¸  GPUæ£€æµ‹å¤±è´¥: {e}')

print('ğŸ¯ è®¾å¤‡æ˜ å°„éªŒè¯å®Œæˆï¼Œå¯åŠ¨Rayè®­ç»ƒ...')
"

# === æ„å»ºè®­ç»ƒå‘½ä»¤ ===
# æ³¨æ„ï¼šRayä¼šé‡æ–°æ˜ å°„GPUåºå·ï¼Œç‰©ç†GPU4,5,6,7å°†å˜ä¸ºé€»è¾‘GPU0,1,2,3
# ä½¿ç”¨æ›´ç®€æ´çš„æ–¹å¼ä¼ é€’å‚æ•°ï¼Œé¿å…å¼•å·é—®é¢˜
train_params=(
    "algorithm.adv_estimator=grpo"
    "algorithm.norm_adv_by_std_in_grpo=true"
    "algorithm.use_kl_in_reward=false"
    "data.train_files=/home/jovyan2/query_rl/data/sales_rag/train.parquet"
    "data.val_files=/home/jovyan2/query_rl/data/sales_rag/val.parquet"
    "data.train_batch_size=16"
    "data.max_prompt_length=128"
    "data.max_response_length=256"
    "data.filter_overlong_prompts=true"
    "data.truncation=error"
    "+data.data_source=sales_rag_hybrid"
    "data.shuffle=true"
    "actor_rollout_ref.model.path=/home/jovyan2/query_rl/model/Qwen3-8B"
    "actor_rollout_ref.model.use_remove_padding=true"
    "actor_rollout_ref.model.enable_gradient_checkpointing=true"
    "actor_rollout_ref.actor.optim.lr=1e-6"
    "actor_rollout_ref.actor.ppo_mini_batch_size=8"
    "actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=2"
    "actor_rollout_ref.actor.use_kl_loss=true"
    "actor_rollout_ref.actor.kl_loss_coef=0.001"
    "actor_rollout_ref.actor.kl_loss_type=low_var_kl"
    "actor_rollout_ref.actor.entropy_coeff=0"
    "actor_rollout_ref.actor.fsdp_config.param_offload=true"
    "actor_rollout_ref.actor.fsdp_config.optimizer_offload=true"
    "actor_rollout_ref.rollout.name=vllm"
    "actor_rollout_ref.rollout.gpu_memory_utilization=0.5"
    "actor_rollout_ref.rollout.tensor_model_parallel_size=1"
    "actor_rollout_ref.rollout.n=2"
    "actor_rollout_ref.rollout.temperature=0.7"
    "actor_rollout_ref.rollout.top_p=0.9"
    "actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=8"
    "actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=8"
    "trainer.critic_warmup=0"
    "trainer.logger=[\"console\"]"
    "trainer.project_name=sales_rag_hybrid_grpo_fixed"
    "trainer.experiment_name=qwen3_8b_hybrid_grpo_query_rewrite_v3_1"
    "trainer.n_gpus_per_node=4"
    "trainer.nnodes=1"
    "trainer.save_freq=50"
    "trainer.test_freq=10"
    "trainer.total_epochs=20"
    "trainer.default_local_dir=checkpoints/SalesRAG_Hybrid_GRPO_Fixed/query_rewrite"
    "+algorithm.hybrid_grpo.enable=true"
    "+algorithm.hybrid_grpo.grpo_weight=0.7"
    "+algorithm.hybrid_grpo.auxiliary_weight=0.3"
    "+algorithm.hybrid_grpo.enable_dynamic_weight=true"
    "+algorithm.hybrid_grpo.weight_decay_rate=0.4"
    "+algorithm.hybrid_grpo.min_auxiliary_weight=0.1"
    "+algorithm.hybrid_grpo.auxiliary_centralization=true"
    "+algorithm.hybrid_grpo.auxiliary_normalization=std"
    "+algorithm.hybrid_grpo.scoring_model=GPT-5"
    "+algorithm.hybrid_grpo.group_size=5"
    "+seed=42"
)

echo "ğŸš€ æ‰§è¡Œè®­ç»ƒå‘½ä»¤..."
echo "ğŸ“Š æ³¨æ„ï¼šç‰©ç†GPU 4,5,6,7 å°†æ˜ å°„ä¸ºé€»è¾‘GPU 0,1,2,3"
echo "ğŸ’¡ å†…å­˜ç®¡ç†ï¼šgpu_memory_utilization=0.5 å¯æ ¹æ®å®é™…æ˜¾å­˜è°ƒæ•´"

# === æ‰§è¡Œè®­ç»ƒ ===
# ä½¿ç”¨æ›´å¯é çš„æ–¹å¼æ‰§è¡Œå‘½ä»¤
python3 -m verl.trainer.main_ppo "${train_params[@]}"