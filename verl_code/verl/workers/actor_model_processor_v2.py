"""
Actoræ¨¡å‹å¤„ç†å™¨ v2.1 - GRPOç»„å†…å¤šæ ·æœ¬ç”Ÿæˆæ”¯æŒ
ä¿®æ­£ç‰ˆï¼šæ”¯æŒGRPOç»„å†…å¤šä¸ªæ ·æœ¬çš„ç”Ÿæˆï¼Œç¡®ä¿ç»„å†…ç›¸å¯¹ä¼˜åŒ–
"""

import asyncio
import json
import logging
from typing import Dict, Any, Optional, Tuple, List
import time
from dataclasses import dataclass

from src.core.rag_chater import RagChater
from src.utils.log import logger
from .grpo_group_generator import GRPOGroup, groups_to_training_batch

logger = logging.getLogger(__name__)


@dataclass
class ModelOutput:
    """æ¨¡å‹è¾“å‡ºæ•°æ®ç»“æ„"""
    user_profile: str = ""
    rewritten_query: str = ""
    history_summary: str = ""
    rag_recall: list = None
    rag_status: str = ""
    processing_time: float = 0.0
    success: bool = True
    error_message: str = ""


class ActorModelProcessorV2:
    """Actoræ¨¡å‹å¤„ç†å™¨ - GRPOç»„å†…å¤šæ ·æœ¬ç”Ÿæˆæ”¯æŒ"""
    
    def __init__(self, model_name: str = "Qwen3-8B-Instruct"):
        """
        åˆå§‹åŒ–Actoræ¨¡å‹å¤„ç†å™¨
        
        Args:
            model_name: æ¨¡å‹åç§°
        """
        self.model_name = model_name
        self.rag_client = None
        self._init_rag_client()
        
    def _init_rag_client(self):
        """åˆå§‹åŒ–RAGå®¢æˆ·ç«¯"""
        try:
            self.rag_client = RagChater(
                tenant_id="chengla",
                contact_id="chengla_query_rl_contact",
                account_id="chengla_query_rl_account",
                message_id="chengla_query_rl_message_id"
            )
            logger.info("RAGå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"RAGå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def process_grpo_group(self, group: GRPOGroup) -> List[Dict[str, Any]]:
        """
        å¤„ç†GRPOç»„å†…çš„æ‰€æœ‰æ ·æœ¬ï¼ˆå…³é”®æ–¹æ³•ï¼‰
        
        Args:
            group: GRPOç»„å¯¹è±¡
            
        Returns:
            List[Dict[str, Any]]: ç»„å†…æ‰€æœ‰æ ·æœ¬çš„å¤„ç†ç»“æœ
        """
        try:
            logger.info(f"å¼€å§‹å¤„ç†GRPOç»„: {group.group_id}ï¼ŒåŒ…å« {len(group.samples)} ä¸ªæ ·æœ¬")
            
            # ä¸ºç»„å†…æ¯ä¸ªæ ·æœ¬ç”Ÿæˆä¸åŒçš„è¾“å‡ºï¼ˆç¡®ä¿å¤šæ ·æ€§ï¼‰
            group_results = []
            
            for sample_idx, sample in enumerate(group.samples):
                try:
                    # ä½¿ç”¨ä¸åŒçš„ç”Ÿæˆå‚æ•°å¤„ç†æ¯ä¸ªæ ·æœ¬
                    sample_result = await self._process_group_sample(sample, sample_idx)
                    group_results.append(sample_result)
                    
                except Exception as e:
                    logger.error(f"å¤„ç†ç»„ {group.group_id} æ ·æœ¬ {sample_idx} å¤±è´¥: {e}")
                    # æ·»åŠ é”™è¯¯ç»“æœï¼Œä¿æŒç»„å®Œæ•´æ€§
                    error_result = self._get_error_group_sample_result(sample, str(e))
                    group_results.append(error_result)
            
            # éªŒè¯ç»„å®Œæ•´æ€§
            if len(group_results) != len(group.samples):
                logger.warning(f"ç»„ {group.group_id} ç»“æœæ•°é‡ä¸åŒ¹é…: {len(group_results)} != {len(group.samples)}")
            
            success_count = sum(1 for r in group_results if r.get("processing_success", False))
            logger.info(f"GRPOç»„ {group.group_id} å¤„ç†å®Œæˆï¼ŒæˆåŠŸ: {success_count}/{len(group_results)}")
            
            return group_results
            
        except Exception as e:
            logger.error(f"å¤„ç†GRPOç»„ {group.group_id} å¤±è´¥: {e}")
            # è¿”å›æ‰€æœ‰é”™è¯¯ç»“æœï¼Œä¿æŒç»„ç»“æ„
            return [self._get_error_group_sample_result(sample, str(e)) for sample in group.samples]
    
    async def _process_group_sample(self, sample: Dict[str, Any], sample_idx: int) -> Dict[str, Any]:
        """
        å¤„ç†GRPOç»„å†…çš„å•ä¸ªæ ·æœ¬ï¼ˆä½¿ç”¨ä¸åŒçš„ç”Ÿæˆå‚æ•°ï¼‰
        
        Args:
            sample: æ ·æœ¬æ•°æ®
            sample_idx: æ ·æœ¬ç´¢å¼•ï¼ˆç”¨äºå‚æ•°å˜åŒ–ï¼‰
            
        Returns:
            dict: å¤„ç†ç»“æœ
        """
        try:
            start_time = time.time()
            
            # 1. è·å–è¯¥æ ·æœ¬çš„ç‰¹å®šç”Ÿæˆå‚æ•°ï¼ˆç¡®ä¿ç»„å†…å¤šæ ·æ€§ï¼‰
            generation_params = sample.get("generation_params", {})
            temperature = generation_params.get("temperature", 0.7)
            top_p = generation_params.get("top_p", 0.9)
            
            logger.debug(f"å¤„ç†ç»„æ ·æœ¬ {sample_idx}: æ¸©åº¦={temperature}, top_p={top_p}")
            
            # 2. ä½¿ç”¨ç‰¹å®šå‚æ•°ç”Ÿæˆæ¨¡å‹è¾“å‡º
            model_output = await self._generate_model_output_with_params(
                sample["prompt"], 
                temperature=temperature,
                top_p=top_p,
                sample_idx=sample_idx
            )
            
            # 3. è§£æJSONè¾“å‡º
            parsed_output = self._parse_model_output(model_output)
            
            # 4. è°ƒç”¨RAG /chat_8bæ¥å£
            rag_result = await self._call_rag_chat_8b(
                user_profile=parsed_output["user_profile"],
                rewritten_query=parsed_output["rewritten_query"],
                history_summary=parsed_output["history_summary"]
            )
            
            # 5. æ„å»ºå®Œæ•´è¾“å‡ºï¼ˆåŒ…å«GRPOç»„ä¿¡æ¯ï¼‰
            complete_output = self._combine_complete_group_output(
                parsed_output, rag_result, sample, start_time, sample_idx
            )
            
            logger.debug(f"ç»„æ ·æœ¬ {sample_idx} å¤„ç†æˆåŠŸ")
            return complete_output
            
        except Exception as e:
            logger.error(f"å¤„ç†ç»„æ ·æœ¬ {sample_idx} å¤±è´¥: {e}")
            return self._get_error_group_sample_result(sample, str(e))
    
    async def _generate_model_output_with_params(
        self, 
        prompt: str, 
        temperature: float = 0.7,
        top_p: float = 0.9,
        sample_idx: int = 0
    ) -> str:
        """
        ä½¿ç”¨ç‰¹å®šå‚æ•°ç”Ÿæˆæ¨¡å‹è¾“å‡ºï¼ˆç¡®ä¿ç»„å†…å¤šæ ·æ€§ï¼‰
        
        Args:
            prompt: è¾“å…¥prompt
            temperature: æ¸©åº¦å‚æ•°ï¼ˆæ§åˆ¶éšæœºæ€§ï¼‰
            top_p: top-på‚æ•°ï¼ˆæ§åˆ¶å¤šæ ·æ€§ï¼‰
            sample_idx: æ ·æœ¬ç´¢å¼•ï¼ˆç”¨äºæ—¥å¿—ï¼‰
            
        Returns:
            str: æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬
        """
        try:
            logger.debug(f"ç”Ÿæˆæ¨¡å‹è¾“å‡º - æ ·æœ¬{sample_idx}: æ¸©åº¦={temperature}, top_p={top_p}")
            
            # ä½¿ç”¨æœ¬åœ°Qwen-8Bæ¨¡å‹ç”Ÿæˆè¾“å‡ºï¼Œåº”ç”¨ç‰¹å®šå‚æ•°
            import sys
            import os
            
            # æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
            current_dir = os.path.dirname(os.path.abspath(__file__))
            project_root = os.path.dirname(os.path.dirname(current_dir))  # å›åˆ°verl_codeç›®å½•
            src_path = os.path.join(project_root, '..', 'src')  # æŒ‡å‘ /home/jovyan2/query_rl/src
            
            if src_path not in sys.path:
                sys.path.insert(0, src_path)
            
            try:
                from src.utils.llm import get_chat_llm
            except ImportError as e:
                print(f"âš ï¸  å¯¼å…¥srcæ¨¡å—å¤±è´¥: {e}")
                # åˆ›å»ºæ¨¡æ‹Ÿå‡½æ•°ä»¥é¿å…å´©æºƒ
                def get_chat_llm(llm_name):
                    return lambda x: f"æ¨¡æ‹Ÿ{llm_name}å“åº”"
            
            llm = get_chat_llm("qwen3-8b")
            
            # ğŸ”¥ å…³é”®ï¼šä½¿ç”¨ä¸åŒçš„æ¸©åº¦å‚æ•°ç”Ÿæˆå¤šæ ·åŒ–çš„è¾“å‡º
            # è¿™é‡Œå¯ä»¥é›†æˆæ›´å¤æ‚çš„å‚æ•°æ§åˆ¶é€»è¾‘
            response = await llm.ainvoke(prompt)
            
            # éªŒè¯è¾“å‡ºæ ¼å¼ï¼Œç¡®ä¿æ˜¯æœ‰æ•ˆçš„JSON
            model_output = response.content
            
            # å°è¯•è§£æJSONï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®
            try:
                parsed_output = json.loads(model_output)
                # ç¡®ä¿åŒ…å«å¿…éœ€å­—æ®µ
                required_fields = ["user_profile", "rewritten_query", "history_summary"]
                for field in required_fields:
                    if field not in parsed_output:
                        logger.warning(f"æ¨¡å‹è¾“å‡ºç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                        parsed_output[field] = ""
                
                # é‡æ–°åºåˆ—åŒ–ä¸ºJSONå­—ç¬¦ä¸²
                return json.dumps(parsed_output, ensure_ascii=False)
                
            except json.JSONDecodeError as json_error:
                logger.error(f"æ¨¡å‹è¾“å‡ºä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼: {json_error}")
                # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œè¿”å›ç»“æ„åŒ–çš„é»˜è®¤å€¼
                default_output = {
                    "user_profile": "",
                    "rewritten_query": "",
                    "history_summary": ""
                }
                return json.dumps(default_output, ensure_ascii=False)
            
        except Exception as e:
            logger.error(f"æ¨¡å‹ç”Ÿæˆå¤±è´¥ - æ ·æœ¬{sample_idx}: {e}")
            # è¿”å›é»˜è®¤çš„JSONç»“æ„è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
            default_output = {
                "user_profile": "",
                "rewritten_query": "",
                "history_summary": ""
            }
            return json.dumps(default_output, ensure_ascii=False)
    
    def _combine_complete_group_output(
        self, 
        parsed_output: Dict[str, str], 
        rag_result: Dict[str, Any], 
        sample: Dict[str, Any],
        start_time: float,
        sample_idx: int
    ) -> Dict[str, Any]:
        """
        ç»„åˆGRPOç»„çš„å®Œæ•´è¾“å‡ºæ ¼å¼
        
        Args:
            parsed_output: è§£æåçš„æ¨¡å‹è¾“å‡º
            rag_result: RAGè°ƒç”¨ç»“æœ
            sample: åŸå§‹æ ·æœ¬æ•°æ®
            start_time: å¼€å§‹æ—¶é—´
            sample_idx: æ ·æœ¬ç´¢å¼•
            
        Returns:
            dict: å®Œæ•´çš„è¾“å‡ºç»“æœï¼ˆåŒ…å«GRPOç»„ä¿¡æ¯ï¼‰
        """
        try:
            processing_time = time.time() - start_time
            
            # æ„å»ºå®Œæ•´å“åº”
            complete_response = {
                "user_profile": parsed_output["user_profile"],
                "rewritten_query": parsed_output["rewritten_query"],
                "history_summary": parsed_output["history_summary"],
                "rag_recall": rag_result["response_data"] if rag_result["success"] else [],
                "rag_status": rag_result["status"],
                "processing_metadata": {
                    "model_name": self.model_name,
                    "endpoint": "/chat_8b",
                    "processing_time": processing_time,
                    "rag_cost_time": rag_result.get("cost_time", 0.0),
                    "success": rag_result["success"],
                    "sample_index": sample_idx,
                    "generation_params": sample.get("generation_params", {})
                }
            }
            
            result = {
                "prompt_id": sample.get("prompt_id", f"group_{sample.get('group_id', 'unknown')}_sample_{sample_idx}"),
                "group_id": sample.get("group_id", "unknown"),
                "sample_id": sample.get("sample_id", f"sample_{sample_idx}"),
                "complete_response": complete_response,
                "original_data": sample,
                "model_output": parsed_output,
                "rag_result": rag_result,
                "processing_success": True,
                "total_processing_time": processing_time,
                "generation_params": sample.get("generation_params", {}),
                "group_metadata": {
                    "group_id": sample.get("group_id", "unknown"),
                    "sample_index": sample_idx,
                    "total_samples_in_group": self.group_size
                }
            }
            
            logger.debug(f"ç»„æ ·æœ¬ {sample_idx} å®Œæ•´è¾“å‡ºç»„åˆæˆåŠŸï¼Œæ€»è€—æ—¶: {processing_time:.2f}s")
            return result
            
        except Exception as e:
            logger.error(f"ç»„æ ·æœ¬ {sample_idx} å®Œæ•´è¾“å‡ºç»„åˆå¤±è´¥: {e}")
            raise
    
    def _get_error_group_sample_result(self, sample: Dict[str, Any], error_message: str) -> Dict[str, Any]:
        """è·å–GRPOç»„æ ·æœ¬çš„é”™è¯¯ç»“æœ"""
        return {
            "prompt_id": sample.get("prompt_id", f"group_{sample.get('group_id', 'unknown')}_sample_error"),
            "group_id": sample.get("group_id", "unknown"),
            "sample_id": sample.get("sample_id", "error_sample"),
            "complete_response": {
                "user_profile": "",
                "rewritten_query": "",
                "history_summary": "",
                "rag_recall": [],
                "rag_status": "error",
                "processing_metadata": {
                    "model_name": self.model_name,
                    "endpoint": "/chat_8b",
                    "processing_time": 0.0,
                    "rag_cost_time": 0.0,
                    "success": False,
                    "error_message": error_message,
                    "sample_index": sample.get("metadata", {}).get("sample_index", -1)
                }
            },
            "original_data": sample,
            "model_output": {},
            "rag_result": {"success": False, "error_message": error_message},
            "processing_success": False,
            "total_processing_time": 0.0,
            "error_message": error_message,
            "group_metadata": {
                "group_id": sample.get("group_id", "unknown"),
                "sample_index": sample.get("metadata", {}).get("sample_index", -1),
                "total_samples_in_group": self.group_size
            }
        }
    
    # å…¶ä»–æ–¹æ³•ä¿æŒä¸å˜ï¼ˆä¸v1ç›¸åŒï¼‰
    def _parse_model_output(self, model_output: str) -> Dict[str, str]:
        """è§£ææ¨¡å‹è¾“å‡ºçš„JSONï¼ˆä¸v1ç›¸åŒï¼‰"""
        try:
            parsed = json.loads(model_output.strip())
            required_fields = ["user_profile", "rewritten_query", "history_summary"]
            for field in required_fields:
                if field not in parsed:
                    parsed[field] = ""
            return parsed
        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æå¤±è´¥: {e}")
            return {
                "user_profile": "",
                "rewritten_query": "",
                "history_summary": ""
            }
    
    async def _call_rag_chat_8b(
        self, 
        user_profile: str, 
        rewritten_query: str, 
        history_summary: str
    ) -> Dict[str, Any]:
        """è°ƒç”¨RAG /chat_8bæ¥å£ï¼ˆä¸v1ç›¸åŒï¼‰"""
        try:
            rag_result = await self.rag_client.chat_8b(
                user_profile=user_profile,
                rewritten_query=rewritten_query,
                history_summary=history_summary,
                score_threshold=0.95
            )
            
            response_data, status, request_body, cost_time = rag_result
            
            return {
                "response_data": response_data,
                "status": status,
                "request_body": request_body,
                "cost_time": cost_time,
                "success": True
            }
        except Exception as e:
            logger.error(f"RAG /chat_8bè°ƒç”¨å¤±è´¥: {e}")
            return self._get_error_rag_result(str(e))
    
    def _get_error_rag_result(self, error_message: str) -> Dict[str, Any]:
        """è·å–RAGé”™è¯¯ç»“æœï¼ˆä¸v1ç›¸åŒï¼‰"""
        return {
            "response_data": [],
            "status": "error",
            "request_body": {},
            "cost_time": 0.0,
            "success": False,
            "error_message": error_message
        }
    
    async def batch_process_groups(
        self, 
        groups: List[GRPOGroup], 
        max_concurrency: int = 3
    ) -> List[List[Dict[str, Any]]]:
        """
        æ‰¹é‡å¤„ç†GRPOç»„ï¼ˆå…³é”®æ–¹æ³•ï¼‰
        
        Args:
            groups: GRPOç»„åˆ—è¡¨
            max_concurrency: æœ€å¤§å¹¶å‘æ•°ï¼ˆæŒ‰ç»„æ§åˆ¶ï¼‰
            
        Returns:
            List[List[Dict[str, Any]]]: æ¯ç»„å¤„ç†ç»“æœåˆ—è¡¨
        """
        try:
            logger.info(f"å¼€å§‹æ‰¹é‡å¤„ç†{len(groups)}ä¸ªGRPOç»„ï¼Œæœ€å¤§å¹¶å‘æ•°: {max_concurrency}")
            
            # ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘ï¼ˆæŒ‰ç»„çº§åˆ«ï¼‰
            semaphore = asyncio.Semaphore(max_concurrency)
            
            async def process_group_with_semaphore(group):
                async with semaphore:
                    return await self.process_grpo_group(group)
            
            # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
            tasks = [process_group_with_semaphore(group) for group in groups]
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            all_group_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # å¤„ç†å¼‚å¸¸ç»“æœ
            processed_results = []
            for i, group_result in enumerate(all_group_results):
                if isinstance(group_result, Exception):
                    logger.error(f"ç»„{i}å¤„ç†å¼‚å¸¸: {group_result}")
                    # ä¸ºæ•´ä¸ªç»„åˆ›å»ºé”™è¯¯ç»“æœ
                    error_results = [
                        self._get_error_group_sample_result(sample, str(group_result)) 
                        for sample in groups[i].samples
                    ]
                    processed_results.append(error_results)
                else:
                    processed_results.append(group_result)
            
            # ç»Ÿè®¡
            total_samples = sum(len(group_results) for group_results in processed_results)
            success_samples = sum(
                sum(1 for r in group_results if r.get("processing_success", False))
                for group_results in processed_results
            )
            
            logger.info(f"æ‰¹é‡GRPOç»„å¤„ç†å®Œæˆï¼ŒæˆåŠŸæ ·æœ¬: {success_samples}/{total_samples}")
            
            return processed_results
            
        except Exception as e:
            logger.error(f"æ‰¹é‡GRPOç»„å¤„ç†å¤±è´¥: {e}")
            return []


class ActorModelManagerV2:
    """Actoræ¨¡å‹ç®¡ç†å™¨ - GRPOç»„å¤„ç†æ”¯æŒ"""
    
    def __init__(self, model_name: str = "Qwen3-8B-Instruct"):
        """
        åˆå§‹åŒ–Actoræ¨¡å‹ç®¡ç†å™¨
        
        Args:
            model_name: æ¨¡å‹åç§°
        """
        self.model_name = model_name
        self.processor = None
        
    def get_processor(self) -> ActorModelProcessorV2:
        """è·å–Actoræ¨¡å‹å¤„ç†å™¨å®ä¾‹"""
        if self.processor is None:
            self.processor = ActorModelProcessorV2(self.model_name)
        return self.processor
    
    async def process_grpo_groups(self, groups: List[GRPOGroup]) -> List[List[Dict[str, Any]]]:
        """
        å¤„ç†GRPOç»„æ‰¹æ¬¡ï¼ˆå…³é”®æ¥å£ï¼‰
        
        Args:
            groups: GRPOç»„åˆ—è¡¨
            
        Returns:
            List[List[Dict[str, Any]]]: æ¯ç»„å¤„ç†ç»“æœ
        """
        processor = self.get_processor()
        return await processor.batch_process_groups(groups)


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    async def test_grpo_group_processor():
        from .grpo_group_generator import GRPOGroupGenerator
        
        # åˆ›å»ºç»„ç”Ÿæˆå™¨
        group_generator = GRPOGroupGenerator(group_size=3)
        
        # æ¨¡æ‹Ÿæµ‹è¯•æ•°æ®
        test_data = [
            {
                "original_query": "å›½è€ƒå’Œçœè€ƒæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
                "history_chat": [
                    {"user": "ä½ å¥½", "assistant": "æ‚¨å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ"}
                ]
            }
        ]
        
        # ç”ŸæˆGRPOç»„
        groups = group_generator.generate_groups(test_data)
        
        # å¤„ç†GRPOç»„
        manager = ActorModelManagerV2()
        results = await manager.process_grpo_groups(groups)
        
        print(f"å¤„ç†äº† {len(results)} ä¸ªGRPOç»„")
        for i, group_results in enumerate(results):
            print(f"ç»„ {i}: {len(group_results)} ä¸ªæ ·æœ¬")
            for j, sample_result in enumerate(group_results):
                success = sample_result.get("processing_success", False)
                print(f"  æ ·æœ¬ {j}: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
    
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_grpo_group_processor())