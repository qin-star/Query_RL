# SFT训练数据格式对比说明

## 两个版本的区别

### Version 1: 单一任务（Query改写）

**训练目标**：学习如何改写query

**输入格式**：
```
原始问题: 橙啦APP在哪里下载？

用户画像: 用户为西安医学院药学专业大二本科生，正在备考公考...

历史摘要: 用户正在为孩子报名课程，孩子目前在西安医学院读药学本科...

请改写这个问题，使其更适合知识库检索。
```

**输出格式**：
```
橙啦APP在哪里可以下载？
```

**优点**：
- ✅ 任务单一，模型容易学习
- ✅ 输出简洁，易于解析
- ✅ 适合专注于query改写的场景

**缺点**：
- ❌ 需要预先生成user_profile和history_summary
- ❌ 无法端到端训练


---

### Version 2: 多任务输出（你的新需求）

**训练目标**：从对话历史中同时理解并生成三个信息

**输入格式**：
```
请分析以下销售-客户对话历史，生成用户画像、历史摘要和改写问题：

对话历史：
[销售][2025-03-03 20:47:47]：麻烦咱们孩子加老师微信...
[客户][2025-03-03 20:48:25]：和孩子还没联系上
[客户][2025-03-03 20:48:58]：她最近很忙，我给发信息了
...
[客户][2025-03-03 20:51:06]：是孩子上大二
...

请以JSON格式输出分析结果。
```

**输出格式**：
```json
{
  "user_profile": "用户为西安医学院药学专业大二本科生，正在备考公考，关注课程学习方式和学习资源获取。",
  "history_summary": "用户正在为孩子报名课程，孩子目前在西安医学院读药学本科，课程通过橙啦APP进行，用户关心课程下载和学习方式。",
  "rewritten_query": "橙啦APP在哪里可以下载？"
}
```

**优点**：
- ✅ 端到端训练，无需预处理
- ✅ 模型学习更全面的理解能力
- ✅ 三个任务互相促进，提升整体效果
- ✅ 更符合实际应用场景

**缺点**：
- ❌ 训练难度更大，需要更多数据
- ❌ 需要模型能正确生成JSON格式
- ❌ 推理时需要解析JSON输出


---

## 训练数据样本对比

### Version 1 样本示例

```json
{
  "messages": [
    {
      "role": "system",
      "content": "你是一个专业的教育培训知识库查询优化专家..."
    },
    {
      "role": "user",
      "content": "原始问题: 橙啦APP在哪里下载？\n\n用户画像: 用户为西安医学院药学专业大二本科生...\n\n请改写这个问题，使其更适合知识库检索。"
    },
    {
      "role": "assistant",
      "content": "橙啦APP在哪里可以下载？"
    }
  ]
}
```

### Version 2 样本示例

```json
{
  "messages": [
    {
      "role": "system",
      "content": "你是一个专业的教育培训领域智能分析助手..."
    },
    {
      "role": "user",
      "content": "请分析以下销售-客户对话历史，生成用户画像、历史摘要和改写问题：\n\n对话历史：\n[销售][2025-03-03 20:47:47]：麻烦咱们孩子加老师微信...\n..."
    },
    {
      "role": "assistant",
      "content": "{\n  \"user_profile\": \"用户为西安医学院药学专业大二本科生...\",\n  \"history_summary\": \"用户正在为孩子报名课程...\",\n  \"rewritten_query\": \"橙啦APP在哪里可以下载？\"\n}"
    }
  ]
}
```


---

## 建议与选择

### 🎯 推荐使用 Version 2 的场景：

1. **你有完整的对话历史数据**（✅ 你的情况）
2. **希望端到端训练**，减少人工标注
3. **需要模型具备全面的理解能力**
4. **愿意投入更多训练资源**

### 🎯 推荐使用 Version 1 的场景：

1. 只关注query改写质量
2. 训练资源有限
3. 需要快速验证效果
4. 已有预处理的user_profile和history_summary


---

## 训练配置建议

### Version 2 训练参数（ms-swift）

```bash
CUDA_VISIBLE_DEVICES=0 \
swift sft \
    --model Qwen/Qwen3-8B-Instruct \
    --train_type lora \
    --dataset data/sft/chengla_v2/train_latest.jsonl \
    --val_dataset data/sft/chengla_v2/val_latest.jsonl \
    --torch_dtype bfloat16 \
    --num_train_epochs 3 \
    --per_device_train_batch_size 2 \
    --per_device_eval_batch_size 2 \
    --learning_rate 1e-4 \
    --lora_rank 16 \
    --lora_alpha 32 \
    --target_modules all-linear \
    --gradient_accumulation_steps 8 \
    --eval_steps 100 \
    --save_steps 100 \
    --save_total_limit 3 \
    --logging_steps 10 \
    --max_length 2048 \
    --output_dir output/chengla_v2 \
    --warmup_ratio 0.1
```

**关键参数说明**：
- `num_train_epochs=3`: 多任务学习需要更多epoch
- `max_length=2048`: 对话历史较长，需要更大的上下文窗口
- `lora_rank=16`: 稍大的rank应对更复杂的任务


---

## 推理时的使用

### Version 2 推理代码示例

```python
import json
from transformers import AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained("output/chengla_v2/final")
tokenizer = AutoTokenizer.from_pretrained("output/chengla_v2/final")

# 输入对话历史
conversation_history = """
[销售][2025-03-03 20:47:47]：麻烦咱们孩子加老师微信...
[客户][2025-03-03 20:48:25]：和孩子还没联系上
...
"""

messages = [
    {"role": "system", "content": system_prompt},
    {"role": "user", "content": f"请分析以下对话历史...\n\n{conversation_history}"}
]

# 生成
inputs = tokenizer.apply_chat_template(messages, return_tensors="pt")
outputs = model.generate(inputs, max_new_tokens=512)
response = tokenizer.decode(outputs[0], skip_special_tokens=True)

# 解析JSON输出
try:
    result = json.loads(response)
    user_profile = result['user_profile']
    history_summary = result['history_summary']
    rewritten_query = result['rewritten_query']
except:
    print("JSON解析失败，需要检查模型输出")
```


---

## 总结

**你的新需求（Version 2）更适合实际应用场景**：
- ✅ 从原始对话直接生成所需信息
- ✅ 减少人工预处理环节
- ✅ 模型学到更全面的能力

**建议**：
1. 先用 Version 2 训练看效果
2. 如果JSON格式输出不稳定，可以考虑：
   - 增加训练数据量
   - 提高训练epoch
   - 或降级使用 Version 1


